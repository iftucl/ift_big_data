version: '3.5'

services:
    mongo_db:
      container_name: mongo_db
      image: mongo:latest
      ports:
        - 27018:27017
    mongo_seed:
      container_name: mongo_seed
      depends_on:
        - mongo_db
      build: ./DataBases/DBs/SP500Static/.
    mongo_express:
      container_name: mongo_express
      image: mongo-express:latest
      depends_on:
        - mongo_db
      environment:
        - ME_CONFIG_BASICAUTH_USERNAME=mongodb_express
        - ME_CONFIG_BASICAUTH_PASSWORD=mongodb_express
        - ME_CONFIG_MONGODB_SERVER=mongo_db
        - ME_CONFIG_MONGODB_PORT=27017
      ports:
        - '8089:8081'
    postgres_db:
        container_name: postgres_db
        image: postgres:10.5
        environment: 
          - POSTGRES_USER=postgres
          - POSTGRES_PASSWORD=postgres
          - PGUSER=postgres
        logging:
          options:
            max-size: 10m
            max-file: "3"
        ports:
          - '5438:5432'
        volumes:
          - ./postgres-data:/var/lib/postgresql/data
        healthcheck:
          test: ["CMD-SHELL", "pg_isready"]
          interval: 10s
          timeout: 5s
          retries: 5          
    postgres_seed:
      container_name: postgres_seed
      restart: on-failure
      environment:
        POSTGRES_DATABASE: postgres_feeder
        POSTGRES_HOST: postgres_feeder
        POSTGRES_PORT: 5432
        POSTGRES_USER: postgres_feeder
        POSTGRES_PASSWORD: postgres_feeder
      depends_on:
        postgres_db:
          condition: service_healthy
      build: 
        dockerfile: ./DataBases/DBs/Equity/Dockerfile
    pgadmin:
      container_name: pg_admin
      image: dpage/pgadmin4
      environment:
        PGADMIN_DEFAULT_EMAIL: admin@admin.com
        PGADMIN_DEFAULT_PASSWORD: root
      ports:
        - "5050:80"
    jenkins:
      container_name: r_jenkins
      build: 
        context: ./
        additional_contexts:
          assets_jenkins: ./Schedulers/jenkins
        dockerfile: ./Scripts/Dockerfile
      user: root      
      command: java -DJENKINS_HOME=/home/.jenkins -jar /home/jenkins/jenkins.jar --httpPort=9899
      volumes:
        - type: bind
          source: ./Scripts/R/
          target: /opt/apps/batched/R/
        - type: bind
          source: ./Scripts/Python/
          target: /opt/apps/batched/Python/
      ports:
        - 9999:9899
    zookeeper:
      image: confluentinc/cp-zookeeper:7.3.2      
      container_name: zoo_keeper
      ports:
        - 2181:2181
      environment:
        ZOOKEEPER_CLIENT_PORT: 2181
        ZOOKEEPER_SERVER_ID: 1
        ZOOKEEPER_SERVERS: zoo_keeper:2888:3888
    kafka:
      image: confluentinc/cp-kafka:7.3.2
      container_name: kafka
      ports:
        - 9092:9092
        - 29092:29092
        - 9991:9999
      environment:
        KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
        KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
        KAFKA_ZOOKEEPER_CONNECT: "zoo_keeper:2181"
        KAFKA_BROKER_ID: 1
        KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
        KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
        KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
        KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
        KAFKA_JMX_PORT: 9999
        KAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}
        KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
        KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
      depends_on:
        - zookeeper
    kafkaconnect:
      build:
        context: .
        dockerfile: ./DataBases/Kafka/Dockerfile
      ports:
        - "35000:35000"
      hostname: connect
      container_name: connect
      depends_on:
        - zookeeper
        - kafka
      environment:
        KAFKA_JMX_PORT: 35000
        KAFKA_JMX_HOSTNAME: localhost
        CONNECT_BOOTSTRAP_SERVERS: "kafka:29092"
        CONNECT_REST_ADVERTISED_HOST_NAME: connect
        CONNECT_REST_PORT: 8083
        CONNECT_GROUP_ID: connect-cluster-group
        CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
        CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
        CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
        CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
        CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
        CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
        CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
        CONNECT_ZOOKEEPER_CONNECT: "zoo_keeper:2181"
        CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
        CONNECT_CONNECTIONS_MAX_IDLE_MS: 180000
        CONNECT_METADATA_MAX_AGE_MS: 180000
        CONNECT_AUTO_CREATE_TOPICS_ENABLE: "true"
        CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
        CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
    minio:
      image: minio/minio
      container_name: minio
      environment:
        - MINIO_ROOT_USER=ift_bigdata
        - MINIO_ROOT_PASSWORD=minio_password
        - MINIO_DOMAIN=minio
      ports:
        - 9001:9001
        - 9000:9000
      command: ["server", "/data", "--console-address", ":9001"]
    minio_client:
      container_name: minio_client
      depends_on:
        - minio
      image: minio/mc
      environment:
        - AWS_ACCESS_KEY_ID=ift_bigdata
        - AWS_SECRET_ACCESS_KEY=minio_password
        - AWS_REGION=us-east-1
      entrypoint: >
        /bin/bash -c "
        until (/usr/bin/mc config host add minio http://minio:9000 ift_bigdata minio_password) do echo '...waiting...' && sleep 1; done;
        sleep 10 && /usr/bin/mc rm -r --force minio/icebergwarehouse;
        sleep 10 && /usr/bin/mc mb minio/icebergwarehouse;
        mc anonymous set public minio/icebergwarehouse;
        sleep 10 && /usr/bin/mc rm -r --force minio/iftbigdata;
        sleep 10 && /usr/bin/mc mb minio/iftbigdata;
        mc anonymous set public minio/iftbigdata;
        tail -f /dev/null
        "      
    iceberg_rest:
      container_name: iceberg_rest
      image: tabulario/iceberg-rest
      ports:
        - "8181:8181"
      environment:
        - AWS_ACCESS_KEY_ID=ift_bigdata
        - AWS_SECRET_ACCESS_KEY=minio_password
        - AWS_REGION=us-east-1
        - CATALOG_S3_PATH__STYLE__ACCESS=true
        - CATALOG_WAREHOUSE=s3://icebergwarehouse/
        - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO
        - CATALOG_S3_ENDPOINT=http://minio:9000
      depends_on:
        - minio
    pythonice:
      container_name: pythonice
      image: python:3.9
      working_dir: /app
      command: tail -f /dev/null
      depends_on:
        - minio
        - iceberg_rest
    # Redis Service
    redis:
      image: redis:7.0-alpine
      container_name: redis_service
      ports:
        - "6379:6379" # Expose Redis on localhost for external access (optional)
      volumes:
        - ./redis_data:/data # Persist Redis data
      command: ["redis-server", "--save", "60", "1", "--loglevel", "warning"]
      restart: always
    # Airflow webserver
networks:
  proxynet:
    name: database_network
